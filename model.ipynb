{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT ALL LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
"# Paper link: https://doi.org/10.1016/j.compag.2025.110824. Please do cite the article if you use this in your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pathlib\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from accelerate import Accelerator\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "POP_SIZE = 10\n",
    "N = 30\n",
    "MAX_GEN = 10\n",
    "CROSSOVER_RATE = 0.9        # CR\n",
    "SCALING_FAC  = 0.8         # F\n",
    "save_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "label = {\n",
    "    \"Tomato___Bacterial_spot\": 0,\n",
    "    \"Tomato___Early_blight\": 1,\n",
    "    \"Tomato___Late_blight\": 2,\n",
    "    \"Tomato___Leaf_Mold\": 3,\n",
    "    \"Tomato___Septoria_leaf_spot\": 4,\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\": 5,\n",
    "    \"Tomato___Target_Spot\": 6,\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\": 7,\n",
    "    \"Tomato___Tomato_mosaic_virus\": 8,\n",
    "    \"Tomato___healthy\": 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, label, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item['image'].convert(\"RGB\")  # Ensure image is in RGB format\n",
    "        label = item['label']\n",
    "        \n",
    "        # Apply the transform if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Map the label to the correct index\n",
    "        label_name = list(self.label.keys())[label]\n",
    "        label_idx = self.label[label_name]\n",
    "        \n",
    "        return image, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Path\n",
    "train_path = './tomato/New Plant Diseases Dataset(Augmented)/train'\n",
    "test_path = './tomato/New Plant Diseases Dataset(Augmented)/valid'\n",
    "BATCH_SIZE = 32\n",
    "# Transforms\n",
    "def dataloader():\n",
    "\n",
    "    # Load the dataset\n",
    "    ds = load_dataset(\"./tomato/New Plant Diseases Dataset(Augmented)/\")\n",
    "    train_data = ds[\"train\"]\n",
    "    validation_data = ds[\"validation\"]\n",
    "    \n",
    "    train_transformer = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), #224, 224\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=10), #15\n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "\n",
    "    test_transformer = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), #224, 224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = torch.tensor([0.485, 0.456, 0.406]), \n",
    "                             std = torch.tensor([0.229, 0.224, 0.225])),\n",
    "    ])\n",
    "    \n",
    "    train_ratio = 0.75\n",
    "    \n",
    "    # Create the custom Dataset\n",
    "    train_dataset = CustomDataSet(train_data, label, train_transformer)\n",
    "    test_dataset = CustomDataSet(validation_data, label, train_transformer)\n",
    "\n",
    "    #  Calculate the sizes for each split\n",
    "    dataset_size = len(train_dataset)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    validation_size = dataset_size - train_size\n",
    "    \n",
    "    # Perform the split\n",
    "    train_dataset, validation_dataset = random_split(train_dataset, [train_size, validation_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        # torchvision.datasets.ImageFolder(train_path,transform = train_transformer),\n",
    "        batch_size = BATCH_SIZE, shuffle = True, #pin_memory=True #num_workers = 2,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size = BATCH_SIZE, shuffle = False,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        # torchvision.datasets.ImageFolder(test_path,transform = test_transformer),\n",
    "        batch_size = BATCH_SIZE, shuffle = False, #num_workers = 2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    root=pathlib.Path(train_path)\n",
    "    classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "\n",
    "    return train_loader, val_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Loading Data Set\n",
    "accelerator = Accelerator()\n",
    "device = torch.device(\"cuda:2\")\n",
    "device = accelerator.device\n",
    "train_loader, val_loader, test_loader, classes = dataloader()\n",
    "train_loader, val_loader, test_loader = accelerator.prepare(train_loader, val_loader, test_loader)\n",
    "num_class = len(classes)\n",
    "\n",
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Patch embedding\n",
    "class Embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 # batch_size, \n",
    "                 DR, \n",
    "                 patch_size: int, \n",
    "                 emb_dim: int, \n",
    "                 in_channels: int = 3, \n",
    "                 img_size: int = 224):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_dim = emb_dim\n",
    "        # self.batch_size = batch_size\n",
    "        assert img_size % self.patch_size == 0, f\"Input img must be divisble by patch size {self.patch_size}\"\n",
    "        self.num_patches = (img_size * img_size) // (self.patch_size ** 2)\n",
    "\n",
    "        self.patcher = nn.Conv2d(\n",
    "                in_channels = self.in_channels,\n",
    "                out_channels = self.emb_dim,\n",
    "                kernel_size = self.patch_size,\n",
    "                stride = self.patch_size,\n",
    "                padding = 0\n",
    "                    )\n",
    "        self.flatten = nn.Flatten(2)\n",
    "        \n",
    "        self.cls_token = nn.Parameter(\n",
    "            torch.randn(1, 1, self.emb_dim),\n",
    "            requires_grad = True\n",
    "        )\n",
    "        self.pos_embd = nn.Parameter(\n",
    "            torch.randn(1, self.num_patches + 1, self.emb_dim),\n",
    "            requires_grad = True\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(p = DR)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.batch_size = x.shape[0]\n",
    "        img_res = x.shape[-1]\n",
    "        assert img_res % self.patch_size == 0, f\"Input img must be divisble by patch size {self.patch_size} and current image shape {img_res}\"\n",
    "        cls_token = self.cls_token.expand(self.batch_size, -1, -1)\n",
    "        x = self.patcher(x)\n",
    "        x = self.flatten(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        # x = x.permute(0, 2 , 1)\n",
    "        x = torch.cat((cls_token, x), dim = 1)\n",
    "        x = x + self.pos_embd\n",
    "        x = self.emb_dropout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create ViT Model\n",
    "\n",
    "class MyViT(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                DR,\n",
    "                activation,\n",
    "                patch_size,\n",
    "                emb_dim, \n",
    "                num_layers,\n",
    "                num_heads,\n",
    "                num_classes,\n",
    "                d_ff,\n",
    "                in_channels: int = 3,\n",
    "                img_size: int = 224): #224\n",
    "        super().__init__()\n",
    "        self.mlp_size = d_ff #4 * emb_dim\n",
    "        assert img_size % patch_size == 0, \"Img Size must be divisble patch size\"\n",
    "        self.embedding = Embedding(\n",
    "                                  DR = DR,\n",
    "                                  patch_size = patch_size,\n",
    "                                  emb_dim = emb_dim,\n",
    "                                  in_channels = in_channels,\n",
    "                                  img_size = img_size\n",
    "                                  )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "                                encoder_layer = nn.TransformerEncoderLayer(\n",
    "                                                            d_model = emb_dim,\n",
    "                                                            nhead = num_heads,\n",
    "                                                            dim_feedforward = self.mlp_size,\n",
    "                                                            activation = activation,\n",
    "                                                            batch_first = True,\n",
    "                                                            norm_first = True), # Create a single Transformer Encoder Layer\n",
    "                                                    num_layers = num_layers\n",
    "                                            )\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape = emb_dim, eps = 1e-12),\n",
    "            nn.Linear(in_features = emb_dim,\n",
    "                     out_features = num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.mlp_head(x[:, 0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER-PARAMETER DECLARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "hp = {\n",
    "    'patch_size': {\n",
    "        \"low\": 0,\n",
    "        \"high\": 2,\n",
    "        \"type\": \"choice\",\n",
    "        \"choices\": [8, 4, 16]\n",
    "    },\n",
    "    'emb_size': {\n",
    "        \"low\": 0,\n",
    "        \"high\": 5,\n",
    "        \"type\": \"choice\",\n",
    "        \"choices\": [32, 64, 128, 256, 512, 768],\n",
    "    },\n",
    "    'num_layers': {\n",
    "        \"low\": 4,\n",
    "        \"high\": 16,\n",
    "        \"type\": \"int\",\n",
    "    },\n",
    "    'num_head': {\n",
    "        \"low\": 0,\n",
    "        \"high\": 3,\n",
    "        \"type\": \"choice\",\n",
    "        \"choices\": [2, 4, 8, 16]\n",
    "    },\n",
    "    \"DR\": {\n",
    "        \"low\": 0.1,\n",
    "        \"high\": 0.5,\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    \"acf\": {\n",
    "        \"low\": 0,\n",
    "        \"high\": 1,\n",
    "        \"type\": \"choice\",\n",
    "        \"choices\": [\"relu\", \"gelu\"]\n",
    "    },\n",
    "    \"d_ff\": {\n",
    "        \"low\": 0,\n",
    "        \"high\": 4,\n",
    "        \"type\": \"choice\",\n",
    "        \"choices\": [128, 256, 512, 1024, 3072]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Scheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self,\n",
    "                 optimizer,\n",
    "                 dim_embed,\n",
    "                 warmup_steps,\n",
    "                 steps_in_epoch,\n",
    "                 last_epoch=-1,\n",
    "                 verbose=False):\n",
    "\n",
    "        self.dim_embed = dim_embed\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_param_groups = len(optimizer.param_groups)\n",
    "\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "        self._step_count = (last_epoch+1)*steps_in_epoch\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr = calc_lr(self._step_count, self.dim_embed, self.warmup_steps)\n",
    "        return [lr] * self.num_param_groups\n",
    "\n",
    "\n",
    "def calc_lr(step, dim_embed, warmup_steps):\n",
    "    return dim_embed**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))\n",
    "\n",
    "\n",
    "def evaluate_candidate(candidate, N):\n",
    "    try:\n",
    "        scaler = torch.amp.GradScaler()\n",
    "        # LOAD PARAMS\n",
    "        emb_size = hp[\"emb_size\"][\"choices\"][candidate[\"emb_size\"]] \n",
    "        num_heads = hp[\"num_head\"][\"choices\"][candidate[\"num_head\"]]\n",
    "        d_ff = hp[\"d_ff\"][\"choices\"][candidate[\"d_ff\"]]\n",
    "        num_layers = candidate[\"num_layers\"]\n",
    "        DR = candidate[\"DR\"]\n",
    "        acf = hp[\"acf\"][\"choices\"][candidate[\"acf\"]]\n",
    "        patch_size = hp[\"patch_size\"][\"choices\"][candidate[\"patch_size\"]]\n",
    "\n",
    "        # Create Model\n",
    "        print(\".....Creating model.....\")\n",
    "        model = MyViT(\n",
    "                DR = DR,\n",
    "                activation = acf,\n",
    "                patch_size = patch_size,\n",
    "                emb_dim = emb_size, \n",
    "                num_layers = num_layers,\n",
    "                num_heads = num_heads,\n",
    "                num_classes = num_class,\n",
    "                d_ff = d_ff,\n",
    "                in_channels = 3,\n",
    "                img_size = 256   #224\n",
    "        ).to(device)\n",
    "       \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr = 0.0001, # \n",
    "            betas = (0.9, 0.999),\n",
    "            eps = 1.0e-9,\n",
    "            weight_decay = 1e-4\n",
    "        )\n",
    "        model, optimizer, criterion = accelerator.prepare(model, optimizer, criterion)\n",
    "        warmup_steps = len(train_loader)*5\n",
    "\n",
    "        scheduler = Scheduler(\n",
    "            optimizer,\n",
    "            dim_embed = emb_size,\n",
    "            warmup_steps = warmup_steps,\n",
    "            steps_in_epoch = len(train_loader),\n",
    "        )\n",
    "        N_EPOCHS = N\n",
    "        early_stopping_patience = 4\n",
    "        best_val_loss = float(\"inf\")\n",
    "        print(\"------------TRAIN - VAL - LOOP--------------\")\n",
    "        \n",
    "        total_start_time = time.time()  # Start total timer\n",
    "        \n",
    "        # ------------ TRAIN -- LOOP ----------------\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            # torch.cuda.synchronize()\n",
    "            # torch.cuda.empty_cache()\n",
    "            train_loss = 0.0\n",
    "            model.train()\n",
    "            correctt, totalt = 0, 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=True):\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.amp.autocast(device_type = 'cuda', dtype = torch.bfloat16):      \n",
    "                    y_hat = model(x)\n",
    "                    del x\n",
    "                    loss = criterion(y_hat.to(device), y)\n",
    "                # loss.backward()\n",
    "                scaler.scale(loss).backward() #Change from loss.backward()\n",
    "                # optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                train_loss = train_loss + loss.item() / len(train_loader)\n",
    "    \n",
    "                # optimizer.zero_grad()\n",
    "                # loss.backward()\n",
    "                # optimizer.step()\n",
    "                # scheduler.step()\n",
    "                correctt = correctt + (torch.argmax(y_hat, dim=1) == y).sum().item()\n",
    "                totalt = totalt + y.size(0)\n",
    "\n",
    "            # avg_train_loss = train_loss / len(train_loader)\n",
    "        # ----------- VALIDATION -------------\n",
    "            with torch.no_grad():\n",
    "                correct, total = 0, 0\n",
    "                test_loss = 0.0\n",
    "                all_preds, all_target = [], []\n",
    "                for batch in tqdm(val_loader, desc=\"Testing\"):\n",
    "                    x, y = batch\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    y_hat = model(x)\n",
    "                    del x\n",
    "                    y_hat_cpu = y_hat.to(\"cpu\")\n",
    "                    y_cpu = y.to(\"cpu\")\n",
    "                    loss = criterion(y_hat.to(device), y)\n",
    "                    test_loss = test_loss + loss.item() / len(test_loader)\n",
    "        \n",
    "                    correct = correct + (torch.argmax(y_hat, dim=1) == y).sum().item()\n",
    "                    all_preds.append(torch.argmax(y_hat_cpu, dim = 1).flatten().tolist())\n",
    "                    all_target.append(torch.flatten(y_cpu).tolist())\n",
    "                    total = total + y.size(0)\n",
    "            \n",
    "            test_acc = round(correct / total, 4)\n",
    "            print(f\"Epoch: {epoch + 1}/{N_EPOCHS} Train loss: {train_loss:.2f} Train accuracy: {correctt / totalt * 100:.2f}% Val loss: {test_loss:.2f} Val accuracy: {correct / total * 100:.2f}%\")\n",
    "            # Early Stopping\n",
    "            if test_loss < best_val_loss:\n",
    "                best_val_loss = test_loss\n",
    "                no_improvement_counter = 0\n",
    "            else:\n",
    "                no_improvement_counter = no_improvement_counter + 1\n",
    "                if no_improvement_counter >= early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                    break\n",
    "        total_end_time = time.time()  # End total timer\n",
    "        print(f\"Total time taken: {(total_end_time - total_start_time):.2f} seconds\")\n",
    "        \n",
    "        \n",
    "    except Exception as err:\n",
    "        print(\"ERROR while evaluating candidate!\")\n",
    "        print(err)\n",
    "        return float(\"inf\"), 0.0\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFFERNTIAL EVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clamp(x, low, high):\n",
    "    return max(low, min(x, high))\n",
    "\n",
    "# Generate candidate \n",
    "def generate_candidate():\n",
    "    candidate = {}\n",
    "    for param in hp.keys():\n",
    "        if hp[param][\"type\"] == \"float\":\n",
    "            candidate[param] = random.uniform(hp[param][\"low\"], hp[param][\"high\"])\n",
    "        elif hp[param][\"type\"] == \"int\" or hp[param][\"type\"] == \"choice\":\n",
    "            candidate[param] = random.randint(hp[param][\"low\"], hp[param][\"high\"])\n",
    "    return candidate\n",
    "# Print Candidate\n",
    "def print_candidate(candidate):\n",
    "    readable_candidate = {}\n",
    "    for param in candidate.keys():\n",
    "        if hp[param][\"type\"] == \"choice\":\n",
    "            choice = candidate[param]\n",
    "            readable_candidate[param] = hp[param][\"choices\"][choice]\n",
    "        else:\n",
    "            readable_candidate[param] = candidate[param]\n",
    "    print(readable_candidate)\n",
    "\n",
    "# Generate Population\n",
    "def generate_population(POP_SIZE = POP_SIZE):\n",
    "    return [{\"candidate\": generate_candidate(), \"score\": float(\"inf\"), \"Acc\": 0} for _ in range(POP_SIZE)]\n",
    "def print_population(population):\n",
    "    for p in population:\n",
    "        print(f\"{p['score']:.4f}\", end=\" -> \")\n",
    "        print(f\"{p['Acc']:.4f}\", end = \" -> \")\n",
    "        print_candidate(p['candidate'])\n",
    "\n",
    "\n",
    "# CALCULATE SCORES FOR INITIAL POPULATION\n",
    "def cal_score_intial_pop(population, N):\n",
    "    for i in range(len(population)):\n",
    "        print(f\"-------------------------[ CANDIDATE {i+1:2d} ]-------------------------\")\n",
    "        candidate = population[i][\"candidate\"]\n",
    "        print_candidate(candidate)\n",
    "        score, Acc = evaluate_candidate(candidate , N)\n",
    "        population[i][\"score\"] = score\n",
    "        population[i][\"Acc\"] = Acc\n",
    "    best_index = np.argmin([c[\"score\"] for c in population])\n",
    "    best_score = population[best_index][\"score\"]\n",
    "    best_Acc = population[best_index][\"Acc\"]\n",
    "    best_candidate = population[best_index][\"candidate\"]\n",
    "    return best_candidate, best_score, best_Acc\n",
    "\n",
    "\n",
    "def De(population = generate_population(POP_SIZE = POP_SIZE), MAX_GEN = MAX_GEN, F = SCALING_FAC, CR = CROSSOVER_RATE, N = N):\n",
    "    print_population(population)\n",
    "    best_candidate, best_score, best_Acc = cal_score_intial_pop(population, N)\n",
    "    for G in range(MAX_GEN):\n",
    "        print(f\"=========================[ GENERATION {G+1:2d} ]=========================\")\n",
    "        for i in range(len(population)):\n",
    "            print(f\"-------------------------[ CANDIDATE  {i+1:2d} ]-------------------------\")\n",
    "            target_vector = population[i][\"candidate\"]\n",
    "            print(\"target_vector:\", end=\" \")\n",
    "            print_candidate(target_vector)\n",
    "\n",
    "            # GENERATE\n",
    "            choices = list(range(0, i)) + list(range(i+1, POP_SIZE))  # make chance of picking ith candidate 0\n",
    "            a, b, c = np.random.choice(choices, 3, replace=False)\n",
    "\n",
    "            x1 = population[a][\"candidate\"]\n",
    "            x2 = population[b][\"candidate\"]\n",
    "            x3 = population[c][\"candidate\"]\n",
    "\n",
    "            # MUTATION\n",
    "            donor_vector = {}\n",
    "            for param in target_vector.keys():\n",
    "                donor_vector[param] = x1[param] + F * (x2[param] - x3[param])\n",
    "                if hp[param][\"type\"] in (\"int\", \"choice\"):\n",
    "                    donor_vector[param] = round(donor_vector[param])\n",
    "                donor_vector[param] = clamp(donor_vector[param], hp[param][\"low\"], hp[param][\"high\"])\n",
    "\n",
    "            print(\"donor_vector:\", end=\" \")\n",
    "            print_candidate(donor_vector)\n",
    "\n",
    "            # CROSSOVER\n",
    "            keep_param = random.choice(list(target_vector.keys()))      # R: random param to always keep\n",
    "            trial_vector = {}\n",
    "            for param in target_vector.keys():\n",
    "                r = random.random()\n",
    "                if r < CR or param == keep_param:\n",
    "                    trial_vector[param] = donor_vector[param]\n",
    "                else:\n",
    "                    trial_vector[param] = target_vector[param]\n",
    "\n",
    "            print(\"trial_vector:\", end=\" \")\n",
    "            print_candidate(trial_vector)\n",
    "\n",
    "            # EVALUATE\n",
    "            trial_score, trial_acc = evaluate_candidate(trial_vector, N)\n",
    "            if trial_score < population[i][\"score\"]:\n",
    "                print(f\"{trial_score:0.5f} < {population[i]['score']:0.5f}, picking trial_vector\")\n",
    "                population[i][\"candidate\"] = trial_vector\n",
    "                population[i][\"score\"] = trial_score\n",
    "                population[i][\"Acc\"] = trial_acc\n",
    "            else:\n",
    "                print(f\"{trial_score:0.5f} >= {population[i]['score']:0.5f}, keeping target_vector\")\n",
    "\n",
    "                # FIND BEST TILL NOW\n",
    "        best_index = np.argmin([c[\"score\"] for c in population])\n",
    "        new_best_score = population[best_index][\"score\"]\n",
    "        new_best_acc = population[best_index][\"Acc\"]\n",
    "        if new_best_score < best_score:\n",
    "            print(f\"Best score improved from {best_score:0.4f} to {new_best_score:0.4f}\")\n",
    "            best_score = new_best_score\n",
    "            best_Acc = new_best_acc\n",
    "            best_candidate = population[best_index][\"candidate\"]\n",
    "            print(\"Best candidate: \", end=\"\")\n",
    "            print_candidate(best_candidate)\n",
    "\n",
    "        # WRITE TO CSV LOG\n",
    "        logfilepath = os.path.join(save_dir,f\"logs_p{POP_SIZE}_bs{BATCH_SIZE}.csv\")\n",
    "        if not os.path.isfile(logfilepath):\n",
    "            with open(logfilepath, \"a\") as logfile:\n",
    "                logfile.write(\"gen,\" + \",\".join(map(str, range(len(population)))) + \"\\n\")\n",
    "\n",
    "        with open(logfilepath, \"a\") as logfile:\n",
    "            logfile.write(f\"{G+1},\" + \",\".join(map(str, [c[\"score\"] for c in population])) + \"\\n\")\n",
    "\n",
    "        print(\"\\nPopulation at end of generation\", G+1)\n",
    "        print_population(population)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.cuda.empty_cache()\n",
    "De()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
